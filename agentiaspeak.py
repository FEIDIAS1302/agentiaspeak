import streamlit as st
import requests
from deep_translator import GoogleTranslator
import whisperx
import torch
import os
import difflib
import io
import time
from pydub import AudioSegment

# --- ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="AGENTIA Speak ProÎ²", layout="wide")

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if "history" not in st.session_state:
    st.session_state.history = []
if "edit_list" not in st.session_state:
    st.session_state.edit_list = []

# --- ãƒ‡ã‚¶ã‚¤ãƒ³ ---
st.markdown("""
    <style>
    header {visibility: hidden;}
    .stApp { background-color: #f8f9fa; }
    .char-pill {
        display: inline-block;
        padding: 2px 8px;
        margin: 2px;
        background: #e9ecef;
        border-radius: 4px;
        font-family: monospace;
        font-size: 0.9em;
    }
    </style>
    """, unsafe_allow_html=True)

# --- AIè§£æã‚¨ãƒ³ã‚¸ãƒ³ (WhisperX) ---
@st.cache_resource
def get_whisperx_resources(lang_code):
    device = "cuda" if torch.cuda.is_available() else "cpu"
    # ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã¯Streamlit Cloudã®ãƒ¡ãƒ¢ãƒªåˆ¶é™ã‚’è€ƒæ…®ã— 'base' ã‚’æ¨å¥¨
    model = whisperx.load_model("base", device, compute_type="float32")
    return model, device

def align_audio_with_whisperx(audio_bytes, text, lang_code):
    model, device = get_whisperx_resources(lang_code)
    
    # --- ä¿®æ­£ãƒã‚¤ãƒ³ãƒˆï¼šBytesIOã§ã¯ãªãç‰©ç†ãƒ•ã‚¡ã‚¤ãƒ«ã‚’çµŒç”±ã•ã›ã‚‹ ---
    temp_audio_path = f"temp_align_{int(time.time())}.wav"
    with open(temp_audio_path, "wb") as f:
        f.write(audio_bytes)
    
    try:
        # whisperx.load_audio ã«ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆæ–‡å­—åˆ—ï¼‰ã‚’æ¸¡ã™
        audio_np = whisperx.load_audio(temp_audio_path)
        
        # 2. ãƒˆãƒ©ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
        result = model.transcribe(audio_np, batch_size=1, language=lang_code)
        
        # 3. ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆå®Ÿè¡Œ
        model_a, metadata = whisperx.load_align_model(language_code=lang_code, device=device)
        result = whisperx.align(result["segments"], model_a, metadata, audio_np, device, return_char_alignments=True)
        
        char_data = []
        for segment in result["segments"]:
            if "chars" in segment:
                for char_info in segment["chars"]:
                    if "start" in char_info:
                        char_data.append({
                            "char": char_info["char"],
                            "start": char_info["start"],
                            "end": char_info["end"]
                        })
        return char_data
    
    finally:
        # ä½¿ã„çµ‚ã‚ã£ãŸã‚‰ç¢ºå®Ÿã«å‰Šé™¤
        if os.path.exists(temp_audio_path):
            os.remove(temp_audio_path)

# --- ãƒ¡ã‚¤ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ ---
col_left, col_right = st.columns([2, 1])

with col_right:
    st.subheader("ğŸ“œ ãƒ†ã‚¤ã‚¯å±¥æ­´ & AIè§£æ")
    for item in st.session_state.history:
        with st.expander(f"{item['display_id']}: {item['text'][:15]}..."):
            st.audio(item["data"])
            # AIãŒè§£æã—ãŸå„æ–‡å­—ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚’è¡¨ç¤º
            chars_html = "".join([f"<span class='char-pill'>{c['char']}<br><small>{c['end']:.2f}</small></span>" for c in item["alignment"]])
            st.markdown(chars_html, unsafe_allow_html=True)

with col_left:
    if os.path.exists("logo.png"):
        st.image("logo.png", width=350)
    
    # ç”Ÿæˆã‚»ã‚¯ã‚·ãƒ§ãƒ³
    with st.container():
        st.markdown('<div class="main-card">', unsafe_allow_html=True)
        st.subheader("ğŸ™ï¸ éŸ³å£°ç”Ÿæˆ")
        text_input = st.text_area("æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›", placeholder="ä¾‹: ã“ã‚“ã«ã¡ã¯ã€æœ¬æ—¥ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚’ãŠä¼ãˆã—ã¾ã™ã€‚")
        lang_opt = st.selectbox("è¨€èª", ["æ—¥æœ¬èª", "è‹±èª", "ä¸­å›½èª", "ã‚¹ãƒšã‚¤ãƒ³èª", "éŸ“å›½èª"])
        
        if st.button("ãƒ†ã‚¤ã‚¯ã‚’ç”Ÿæˆ", use_container_width=True):
            api_key = st.secrets.get("FISH_AUDIO_API_KEY")
            if text_input and api_key:
                with st.spinner("ç”Ÿæˆä¸­..."):
                    l_map = {"æ—¥æœ¬èª":"ja","è‹±èª":"en","ä¸­å›½èª":"zh-CN","ã‚¹ãƒšã‚¤ãƒ³èª":"es","éŸ“å›½èª":"ko"}
                    target_lang = l_map[lang_opt]
                    translated = GoogleTranslator(source='ja', target=target_lang).translate(text_input)
                    
                    res = requests.post("https://api.fish.audio/v1/tts",
                        headers={"Authorization":f"Bearer {api_key}","Content-Type":"application/json"},
                        json={"text":translated, "format":"wav", "reference_id":"ffe7a84cf0e243359b28e6c3686bc9af"} # ä¾‹ã¨ã—ã¦ç”·æ€§ID
                    )
                    
                    if res.status_code == 200:
                        audio_bytes = res.content
                        # WhisperXã§ã‚¢ãƒ©ã‚¤ãƒ¡ãƒ³ãƒˆè§£æ
                        alignment = align_audio_with_whisperx(audio_bytes, translated, target_lang)
                        
                        st.session_state.history.insert(0, {
                            "id": int(time.time()),
                            "display_id": f"T-{len(st.session_state.history)+1}",
                            "data": audio_bytes,
                            "text": translated,
                            "alignment": alignment
                        })
                        st.rerun()
        st.markdown('</div>', unsafe_allow_html=True)

    # ç·¨é›†ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    with st.container():
        st.markdown('<div class="main-card">', unsafe_allow_html=True)
        st.subheader("âœ‚ï¸ AIè‡ªå‹•å¸ç€ç·¨é›†")
        if not st.session_state.history:
            st.info("ãƒ†ã‚¤ã‚¯ã‚’ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚")
        else:
            c1, c2 = st.columns(2)
            with c1:
                target_id = st.selectbox("ãƒ†ã‚¤ã‚¯é¸æŠ", [h["id"] for h in st.session_state.history], 
                                         format_func=lambda x: next(h["display_id"] for h in st.session_state.history if h["id"] == x))
                selected_take = next(h for h in st.session_state.history if h["id"] == target_id)
            
            with c2:
                # ã“ã“ãŒAIå¸ç€ã®è‚ï¼šæ–‡å­—ãƒªã‚¹ãƒˆã‹ã‚‰ã‚«ãƒƒãƒˆãƒã‚¤ãƒ³ãƒˆã‚’é¸æŠ
                char_options = [f"{i}: {c['char']} (ã€œ{c['end']:.2f}s)" for i, c in enumerate(selected_take["alignment"])]
                selected_char_idx = st.selectbox("ã‚«ãƒƒãƒˆã™ã‚‹æ–‡å­—ã‚’é¸æŠ", range(len(char_options)), format_func=lambda x: char_options[x])
                
            if st.button("ã“ã®æ–‡å­—ã®ç›´å¾Œã§åˆ‡ã‚Šå‡ºã—ã¦ãƒªã‚¹ãƒˆã«è¿½åŠ "):
                cutoff = selected_take["alignment"][selected_char_idx]["end"]
                # ç°¡æ˜“çš„ã«ã€Œé–‹å§‹0ç§’ã€œé¸æŠã—ãŸæ–‡å­—ã®çµ‚äº†ç§’ã€ã¾ã§ã‚’è¿½åŠ 
                st.session_state.edit_list.append({
                    "id": target_id,
                    "start": 0.0,
                    "end": cutoff,
                    "label": f"{selected_take['display_id']} ã® '{selected_take['alignment'][selected_char_idx]['char']}' ã¾ã§"
                })

            if st.session_state.edit_list:
                st.markdown("---")
                for clip in st.session_state.edit_list:
                    st.text(f"âœ… {clip['label']}")
                
                if st.button("AIçµåˆå®Ÿè¡Œ (ãƒ•ã‚§ãƒ¼ãƒ‰è£œæ­£ã‚ã‚Š)", use_container_width=True):
                    # å‰å›ã®çµåˆãƒ­ã‚¸ãƒƒã‚¯ï¼ˆpydubï¼‰ã‚’å®Ÿè¡Œ
                    final_wav = AudioSegment.empty()
                    for clip in st.session_state.edit_list:
                        source = next(h for h in st.session_state.history if h["id"] == clip["id"])
                        seg = AudioSegment.from_file(io.BytesIO(source["data"]))[clip["start"]*1000 : clip["end"]*1000]
                        final_wav += seg.fade_out(50).fade_in(50) # ã¤ãªãç›®ã‚’50msã§ã‚¯ãƒ­ã‚¹ãƒ•ã‚§ãƒ¼ãƒ‰
                    
                    out_buf = io.BytesIO()
                    final_wav.export(out_buf, format="wav")
                    st.audio(out_buf.getvalue())
                    st.download_button("å®Œæˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜", out_buf.getvalue(), "final.wav", "audio/wav")
        st.markdown('</div>', unsafe_allow_html=True)

st.caption("Â© 2026 Powered by FEIDIAS Inc.")